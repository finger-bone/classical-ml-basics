"use strict";(self.webpackChunknotes_template=self.webpackChunknotes_template||[]).push([[2934],{3837:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Generalized Linear Regression","href":"/classical-ml-basics/docs/generalized-regression","docId":"generalized-regression","unlisted":false},{"type":"category","label":"Binary Classification","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Binary Classification","href":"/classical-ml-basics/docs/binary-classification/","docId":"binary-classification/binary-classification","unlisted":false},{"type":"link","label":"Support Vector Machine","href":"/classical-ml-basics/docs/binary-classification/support-vector-machine","docId":"binary-classification/support-vector-machine","unlisted":false},{"type":"link","label":"Linear Perception Machine","href":"/classical-ml-basics/docs/binary-classification/linear-perception-machine","docId":"binary-classification/linear-perception-machine","unlisted":false},{"type":"link","label":"Covering Algorithm","href":"/classical-ml-basics/docs/binary-classification/covering","docId":"binary-classification/covering","unlisted":false}],"href":"/classical-ml-basics/docs/category/binary-classification"},{"type":"category","label":"Bayes Algorithms","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Bayes Classification","href":"/classical-ml-basics/docs/bayes/bayes-classification","docId":"bayes/bayes-classification","unlisted":false},{"type":"link","label":"Bayes Linear Regression","href":"/classical-ml-basics/docs/bayes/bayes-linear-regression","docId":"bayes/bayes-linear-regression","unlisted":false}],"href":"/classical-ml-basics/docs/category/bayes-algorithms"},{"type":"link","label":"Decision Tree","href":"/classical-ml-basics/docs/decision-tree","docId":"decision-tree","unlisted":false},{"type":"link","label":"Nearest Neighbors","href":"/classical-ml-basics/docs/nearest-neigbours","docId":"nearest-neigbours","unlisted":false},{"type":"category","label":"Feature Reduction","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Feature Reduction","href":"/classical-ml-basics/docs/feature-reduction/","docId":"feature-reduction/feature-reduction","unlisted":false},{"type":"link","label":"PCA","href":"/classical-ml-basics/docs/feature-reduction/pca","docId":"feature-reduction/pca","unlisted":false},{"type":"link","label":"LDA","href":"/classical-ml-basics/docs/feature-reduction/lda","docId":"feature-reduction/lda","unlisted":false},{"type":"link","label":"t-NSE","href":"/classical-ml-basics/docs/feature-reduction/t-nse","docId":"feature-reduction/t-nse","unlisted":false}],"href":"/classical-ml-basics/docs/category/feature-reduction"}]},"docs":{"bayes/bayes-classification":{"id":"bayes/bayes-classification","title":"Bayes Classification","description":"Bayes Algorithm is a simple algorithm based on the Bayes Theorem. It is a simple algorithm that can be used for bith classification and regression problems.","sidebar":"tutorialSidebar"},"bayes/bayes-linear-regression":{"id":"bayes/bayes-linear-regression","title":"Bayes Linear Regression","description":"Bayes Linear Regression is a probabilistic approach that combines Bayes\' Theorem with linear regression. Instead of providing fixed point estimates for the model parameters (such as the coefficients in linear regression), this method incorporates uncertainty by modeling the parameters as probability distributions.","sidebar":"tutorialSidebar"},"binary-classification/binary-classification":{"id":"binary-classification/binary-classification","title":"Binary Classification","description":"Binary Classifiication is the most classic problem in ML.","sidebar":"tutorialSidebar"},"binary-classification/covering":{"id":"binary-classification/covering","title":"Covering Algorithm","description":"TODO","sidebar":"tutorialSidebar"},"binary-classification/linear-perception-machine":{"id":"binary-classification/linear-perception-machine","title":"Linear Perception Machine","description":"TODO","sidebar":"tutorialSidebar"},"binary-classification/support-vector-machine":{"id":"binary-classification/support-vector-machine","title":"Support Vector Machine","description":"Support vector machine is a natural deviation from the linear regression model. In linear regression, we try to fit a line that best fits the data points. In support vector machine, we try to fit a line that best separates the data points.","sidebar":"tutorialSidebar"},"decision-tree":{"id":"decision-tree","title":"Decision Tree","description":"A decision tree is a flowchart-like tree structure where an internal node represents a feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. This is another rule-based algorithm.","sidebar":"tutorialSidebar"},"feature-reduction/feature-reduction":{"id":"feature-reduction/feature-reduction","title":"Feature Reduction","description":"Feature reduction is a means through which the number of features in a dataset can be reduced. This is done by identifying the indiscriminate features and removing them from the dataset. This is done to reduce the complexity of the model and to improve the performance of the model. Feature reduction is also known as feature selection.","sidebar":"tutorialSidebar"},"feature-reduction/lda":{"id":"feature-reduction/lda","title":"LDA","description":"Different from PCA, LDA (Linear Discriminant Analysis) wants to make data with same label clustered together in the low dimension space. LDA assumes that the original data is classified based on the mean value, and different types of value have the same variance. Thus, LDA performs better when the original data is well separated by the mean value.","sidebar":"tutorialSidebar"},"feature-reduction/pca":{"id":"feature-reduction/pca","title":"PCA","description":"PCA means principal component analysis. It is a technique used to reduce the dimensionality of the dataset.","sidebar":"tutorialSidebar"},"feature-reduction/t-nse":{"id":"feature-reduction/t-nse","title":"t-NSE","description":"","sidebar":"tutorialSidebar"},"generalized-regression":{"id":"generalized-regression","title":"Generalized Linear Regression","description":"Regression solves the following question,","sidebar":"tutorialSidebar"},"nearest-neigbours":{"id":"nearest-neigbours","title":"Nearest Neighbors","description":"Nearest Neighbors Algorithm has the simplest idea. It is based on the idea that, if two points are close to each other, they are likely to be in the same class.","sidebar":"tutorialSidebar"}}}}')}}]);